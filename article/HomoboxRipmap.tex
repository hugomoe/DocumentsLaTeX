% contient la description des différentes possibilités pour traiter l'homographie particulière au centre de la décomposition
%simon
\subsubsection{Séparation d'une homographie particulière }

On considère une homographie $h$ de la forme 
\begin{equation*}
h:(x,y)\mapsto \left(\frac{-bx}{1-ax},\frac{-y}{1-ax}\right)
\end{equation*}
On peut décomposer cette homographie en deux applications $h_1 , h_2$
\begin{equation*}
h_1:(x,y) \mapsto \left(\frac{-bx}{1-ax}    ,y\right)~~~~~~h_2:(x,y) \mapsto \left(x,\frac{-y}{1-ax}\right)
\end{equation*}
On obtient $h=h_1  \circ h_2$, ce qui nous donne le schéma suivant 
\begin{equation*}
f\longrightarrow f'=f\circ h_1 \longrightarrow f''=f'\circ h_2
\end{equation*}
Chacune de ces deux transformations ne modifie l'image que dans une seule direction, cela permet d'effectuer des opérations sur des signaux unidimentionnels . Cette méthode n'est en revanche pas séparable.\\ 
La première transformation est une homographie en une dimension que l'on doit réaliser sur chaque ligne.\\ %sur ?
La seconde est un zoom d'un facteur différent sur chaque colonne.

\paragraph{Différentes méthodes de ré-échantillonage naif :}
%peut etre inutile
Le but ici est de présenter plusieurs méthodes permettant réaliser l'homographie par séparation.

\subparagraph{Méthode du point le plus proche :}
Il s'agit de la méthode la plus basique pour effectuer un ré-échantillonnage. On interpole l'image  par une fonction constante par morceau et on réévalue l'image $F\circ h $. Cette méthode est séparable, c'est-à-dire qu'il revient d'effectuer l'homographie $h$ et les deux applications $h_1 , h_2$ successivement.

\subparagraph{Méthode d'interpolation bilinéaire}
Cette méthode permet de réduire l'\emph{aliasing} par rapport à la méthode du point le plus proche, on interpole l'image en utilisant une fonction affine par morceaux $F$ et on évalue ensuite $F\circ h$. Cette méthode est aussi séparable.

%a étoffer
\paragraph{Sous échantillonnage gaussien :}
Dans le cas d'un zoom gaussien on utilise la convolution $f*G_{d}$. Le paramètre $d$ doit être choisi tel que 
\begin{equation*}
z^2 c^2=c^2 + d^2     ~~~~~~~c= 0.8
\end{equation*}
On obtient donc la formule $d=c\sqrt{z^2 - 1}$, nous renvoyons à l'article \cite{morel2011sift} pour les détails de ce raisonnement et une justification de la valeur expérimentale de c.\\

\paragraph{Sous échantillonnage utilisant les images intégrale }
Soit $d>0$, on veut convoler une fonction d'une variable par une approximation d'une gaussienne d'écart type $\delta$.\\
Soit $g_n^d$ le noyau défini par 
\begin{equation*}
g_1^d(t)=\frac{1}{d}\mathds{1}_{]-\frac{d}{2},\frac{d}{2}[}(t) ~~~~~~~g_{n+1}^d= g_n^d * g_1^d
\end{equation*}
Si on pose $G_n^d(x)=\sqrt{n}g_n^d(\sqrt{n} x)$ on peut montrer que 
\begin{equation*}
\widehat{G_n^d}(\omega)\underset{n\rightarrow\infty}{\rightarrow} \exp\left(-\frac{\omega^2 d^2}{12}\right)
\end{equation*}
\begin{proof}
On a $\widehat{g_1^d}(\omega)=\text{sinc}\left(\frac{\omega d}{2}\right)~~$  donc $~~\widehat{g_n^d}(\omega)=\text{sinc}\left(\frac{\omega d}{2}\right)^n~~$ et 
$~~\widehat{G_n^d}(\omega)=\text{sinc}\left(\frac{\omega d}{2\sqrt{n}}\right)^n~~$\\
on obtient le résultat voulu en réalisant un développement limité de cette fonction 
\end{proof}
Si $f,g$ sont deux fonctions continues à support compact et $d>0$ on a le résultat suivant
\begin{equation*}
(f*(g*g_1^d))(y)=\frac{(F^{(1)}*g)(y+\frac{d}{2})-(F^{(1)}*g)(y-\frac{d}{2})}{d}~~~~~~F^{(1)}(x)=\int_{-\infty}^{x}f(y) dy
\end{equation*}
\begin{proof}
Par intégration par partie (au sens des distributions), comme les fonctions $f$ et $g$ sont à support compact on obtient  :
\begin{eqnarray*}
(f * g *g_1^d )(y)&=&\frac{1}{d} \int_{\mathbb{R}} f(x)~(g * \mathds{1}_{]-\frac{d}{2},\frac{d}{2}[})(y-x) dx\\
                 &=& -\frac{1}{d} \int_{\mathbb{R}} F^{(1)}(x)~(g * (-\delta_{\frac{d}{2}}+\delta_{-\frac{d}{2}}))(x-y) dx\\
                 &=& \frac{1}{d} \int_{\mathbb{R}} F^{(1)}(x)~g(x-y-\frac{d}{2} )dx -\frac{1}{d} \int_{\mathbb{R}} F^{(1)}(x)~g(x-y+\frac{d}{2})dx\\
                 &=& \frac{(F^{(1)} * g)(y+\frac{d}{2})-(F^{(1)} * g )(y-\frac{d}{2})}{d}
\end{eqnarray*}
\end{proof}
On peut poser $D_d$ l'opérateur de "dérivation discrète" définit par $D_d f=f*\frac{f(.+\frac{d}{2})-f(.-\frac{d}{2})}{d}$ et réécrire la formule précédente 
\begin{equation*}
f * g *g_1^d =D_d (F^{(1)}*g)
\end{equation*}
On en déduit par récurrence la formule 
\begin{equation*}
(f*g_n^d)(y)=D_d ^n F^{(n)}= \frac{1}{d^n}\underset{0 \le k\le n}{\sum} \binom{n}{k}(-1)^{k} F^{(n)}(y+\frac{(n-2k)d}{2})
\end{equation*}
La fonction $F^{(k)}$ est la somme de la fonction  $F^{(k-1)}$, la seconde égalité se démontre en développant l'opérateur $D_d ^n$ par la formule du binome de Newton.\\
Dans nos algorithmes  on utilisera cette formule pour $n=3$ :
\begin{equation*}
(f*g_3)(y)=\frac{1}{d^3}(F^{(3)}(y+\frac{3d}{2})-3F^{(3)}(y+\frac{d}{2})+3F^{(3)}(y-\frac{d}{2})-F^{(3)}(y-\frac{3d}{2}))
\end{equation*}
On doit cependant calculer une valeur approchée des fonctions $F^{(k)}$  car on ne connait que les échantillons de la fonctions $f$.\\
On peut utiliser la méthode suivante on pose par récurrence
\begin{equation*}
F^{(n+1)}(k)=\underset{l\le k-1}{\sum}F^{(n)}(l)
\end{equation*}
On utilise ensuite une méthode d'interpolation par splines cubiques afin de pouvoir évaluer cette fonction en des valeurs non entière.\\
Une autre méthode consiste à poser 

\begin{equation*}
F^{(0)} (x) =\underset{0\le k \le m-1}{\sum}f_{k} \mathds{1}_{[k,k+1[}(x)
\end{equation*}
$(f_k)_{k=0...m-1}$ sont les termes du signal .On calcule ensuite $F^{(n)}(x)=\int_{-\infty}^{x}F^{(n-1)}(y)dx$ on à par exemple
\begin{equation*}
F^{(1)}(x)=\underset{k\le \lfloor x\rfloor \wedge m~-1}{\sum}f_{k}~~+ f_{\lfloor x\rfloor}
(x-\lfloor x\rfloor)
\end{equation*}
Cette fonction est affine par morceau on peut démontrer la formule suivante par récurrence
\begin{eqnarray*}
F^{(n)}(x) &=& F^{(n)}(\lfloor x\rfloor \wedge m)~~+\mathds{1}_{[0,m[}(x) \underset{0\le k \le n-1}{\sum}F^{(k)}(\lfloor x \rfloor) \frac{(x-\lfloor x \rfloor)^{n-k}}{(n-k)!}\\
          &+&\mathds{1}_{[m,+\infty[}(x)\underset{1\le k \le n-1}{\sum}F^{(k)}(m) \frac{(x-m)^{n-1-k}}{(n-1-k)!}
\end{eqnarray*}
Où la valeur de $F^{(n)}$ se calcule par récurrence on a la relation $\forall k\le m$
\begin{equation*}
F^{(n)}(k+1)=F^{(n)}(k)+\underset{0\le l < n}{\sum} \frac{F^{(l)}(k)}{(n-l)!}
\end{equation*}
Comme dans la méthode précédente on doit calculer une composante constante par morceaux afin d'avoir la valeur de $F^{(n)}$ aux entiers  ainsi qu'un terme polynomial de degré $n$ pour effectuer l'interpolation sur des valeurs non-entières.\\
Dans le cas $n=3$ on obtient les formules
\begin{eqnarray*}
F^{(3)}(x)&=&F^{(3)}(\lfloor x\rfloor \wedge m)~~+\mathds{1}_{[0,m[}(x)(x-\lfloor x \rfloor) \left(F^{(2)}(\lfloor x \rfloor)+ \frac{(x-\lfloor x \rfloor)}{2}\left(F^{(1)}(\lfloor x \rfloor)+\frac{(x-\lfloor x \rfloor)}{3} f_{\lfloor x \rfloor}\right)\right)\\
          &+&\mathds{1}_{[m,+\infty[}(x)(x-\lfloor x \rfloor) \left(F^{(2)}(m)+ \frac{(x-\lfloor x \rfloor)}{2}F^{(1)}(m)\right) \\
F^{(3)}(k)&=&  \underset{0\le l<k}{\sum}\left(F^{(2)}(l)+\frac{F^{(1)}(l)}{2}+\frac{f_{l}}{6} \right)  \\
F^{(2)}(k)&=&  \underset{0\le l<k}{\sum}\left(F^{(1)}(l)+\frac{f_{l}}{2} \right)  \\
F^{(1)}(k)&=&  \underset{0\le l<k}{\sum}f_{l} 
\end{eqnarray*}
Si on fixe $0\le l\le m-1$ et on pose
\begin{equation*}
P_l (x)=F^{3}(l) +(x-l) \left(F^{(2)}(l)+ \frac{(x-l)}{2}\left(F^{(1)}(l)+\frac{(x-l)}{3} f_{l}\right)\right)
\end{equation*}
On obtient alors
\begin{eqnarray*}
P_l (l) &=& F^{(3)}(l) \\
P_l (l+1) &=& F^{(3)}(l+1) \\
P_l '(l) &=& F^{(2)}(l) \\
P_l '(l+1) &=& F^{(2)}(l+1)
\end{eqnarray*}
On peut donc obtenir ces formules en utilisant une méthode d'interpolation de Hermite. La fonction $F^{(3)}$ est la spline de cubique passant par le point $F^{(3)}(k)$ en $k$ avec une dérivé égale à $F^{(2)}(k)$, elle est $\mathcal{C}^2$.\\
Cette méthode a cependant un défaut, l'image est initialement interpolé par une fonction constante par morceau, on a donc utiliser une interpolation linéaire du signal de départ 
\begin{equation*}
F_1 ^{(0)}(x)=\underset{0\le k \le m-1}{\sum} f_k g_2^1 (x-k-\frac{1}{2})=(F_0^{(0)} *g_1^1 )(x)
\end{equation*}
On obtient alors 
\begin{equation*}
F_1 ^{(0)}*g_n^d=(F_0 ^{(0)}*g_1^1)*g_n^d=(F_0 ^{(0)}*g_n^d)*g_1^1=(D_d^n F_0 ^{(n)})*g_1^1=D_1 D_d^n F_0^{(n+1)}
\end{equation*}
L'interpolation supplémentaire peut donc être obtenue en évaluant $F_0^{(n+1)}$. La méthode de calcul est donc la même que dans le cas précédent.\\
Il est possible d'utiliser cette méthode pour obtenir une représentation $F_n^{(0)}$ plus régulière du signal de départ mais la courbe n'est pas  interpolante si $2\le n$.\\
%à faire mieux 
Afin d'implémenter cette méthode nous devons déterminer la valeur du paramètre $d$ en fonction du facteur de zoom local. Nous allons réutiliser les résultats du paragraphe précédent, car la fonction $g_3$ est une bonne approximation d'une gaussienne. L'écart type de $g_1$ est $\sigma_1=\frac{d}{\sqrt{12}}$ donc l'écart type $\sigma_3$ est donné par la formule $\sigma_3=\sqrt{3}\sigma_1=\frac{d}{2}$
donc $d=2c\sqrt{z^2 - 1}$.\\
Dans la pratique on utilisera la formule $d=2\sqrt{(0.8)^2 z^2 - (0.7)^2}$ car les images utilisées ne sont en général pas parfaites.\\

\paragraph{Sur-échantillonage par splines :}
%Pas encore fait
\subparagraph{Splines cubiques de Hermite :}
Si $(x_0,x_1,x_2,x_3)$ et $(y_0,y_1,y_2,y_3)$  permet de construire un polynôme $P$ de degrès 3 tel que  
\begin{equation*}
P(x_1)=y_1~~~~P(x_2)=y_2~~~~P'(x_1)= \frac{y_2-y_0}{x_2 -x_0}~~~~P'(x_2)= \frac{y_3-y_1}{x_3 -x_1}
\end{equation*}
